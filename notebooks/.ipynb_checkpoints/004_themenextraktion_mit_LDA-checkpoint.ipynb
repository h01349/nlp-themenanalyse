{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a819194-33ed-4e8d-bbec-ec027acef7f4",
   "metadata": {},
   "source": [
    "### 004 Themenextraktion mit LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72734ce6-eea3-46e6-9a23-198e554f22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardbibliotheken\n",
    "import ast\n",
    "\n",
    "# Drittanbieter-Bibliotheken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm # Fortschrittsanzeige für Jupyter Notebook\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Funktion zur Berechnung der Coherence Scores für verschiedene Themenanzahlen\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "    print(\"\\nStarte Training und Coherence-Berechnung: Dies kann einen Moment dauern ...\")\n",
    "    coherence_scores = []\n",
    "    models = []\n",
    "\n",
    "    for num_topics in tqdm(range(start, limit + 1, step), desc=\"Trainiere Modelle\"):\n",
    "        tqdm.write(f\"Trainiere Modell mit {num_topics} Themen ...\")\n",
    "\n",
    "        model = gensim.models.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            random_state=42,\n",
    "            passes=10\n",
    "        )\n",
    "\n",
    "        coherence_model = CoherenceModel(\n",
    "            model=model,\n",
    "            texts=texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence=\"c_v\"\n",
    "        )\n",
    "\n",
    "        coherence = coherence_model.get_coherence()\n",
    "        coherence_scores.append(coherence)\n",
    "        models.append(model)\n",
    "\n",
    "        tqdm.write(f\"Modell mit {num_topics} Themen abgeschlossen | Coherence Score: {coherence:.4f}\")\n",
    "\n",
    "    print(\"\\nAlle Modelle wurden erfolgreich trainiert.\\n\")\n",
    "    return models, coherence_scores\n",
    "\n",
    "# CSV-Datei laden (cleaned_data.csv)\n",
    "data = pd.read_csv(\"../data/cleaned_data.csv\")\n",
    "\n",
    "# Textspalte wieder in Listenform bringen\n",
    "data[\"lemmas\"] = data[\"lemmas\"].apply(ast.literal_eval)\n",
    "\n",
    "print(\"Starte Vorbereitung für das LDA-Themenmodell (Dictionary & Korpus) ...\")\n",
    "\n",
    "# Wörterbuch und Bag-of-Words-Korpus erstellen (für gensim.models.LdaModel)\n",
    "lda_dictionary = corpora.Dictionary(data[\"lemmas\"])\n",
    "lda_corpus = [lda_dictionary.doc2bow(text) for text in data[\"lemmas\"]]\n",
    "\n",
    "# Einfaches LDA-Modell (erste Version mit fester Themenanzahl)\n",
    "lda_model = gensim.models.LdaModel(\n",
    "    corpus=lda_corpus,\n",
    "    id2word=lda_dictionary,\n",
    "    num_topics=5, # Test\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "# Parameter für die automatische Themenoptimierung festlegen\n",
    "start, limit, step = 2, 10, 1\n",
    "\n",
    "# Modelle mit verschiedenen Themenanzahlen trainieren und Coherence Scores berechnen\n",
    "models, scores = compute_coherence_values(\n",
    "    dictionary=lda_dictionary,\n",
    "    corpus=lda_corpus,\n",
    "    texts=data[\"lemmas\"],\n",
    "    limit=limit,\n",
    "    start=start,\n",
    "    step=step\n",
    ")\n",
    "\n",
    "# Ausgabe der wichtigsten Themen je Modell\n",
    "print(\"Berechne und zeige Top-Themen je Modell:\")\n",
    "for i, model in enumerate(tqdm(models, desc=\"Top-Themen je Modell\")):\n",
    "    print(f\"\\nModell mit {i + start} Themen\")\n",
    "    topics = model.print_topics(num_words=5)\n",
    "    for topic_id, topic in topics:\n",
    "        print(f\"Thema {topic_id + 1}: {topic}\")\n",
    "\n",
    "# Coherence Scores anzeigen\n",
    "print(\"\\nCoherence Scores für verschiedene Themenanzahlen:\\n\")\n",
    "x_values = range(start, limit + 1, step)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    print(f\"Themenanzahl: {x_values[i]} | Coherence Score: {scores[i]:.4f}\")\n",
    "\n",
    "# Plot: Entwicklung der Coherence Scores\n",
    "plt.plot(x_values, scores, marker=\"o\")\n",
    "plt.xlabel(\"Anzahl der Themen\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"Coherence Score je Anzahl der Themen (LDA)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ec1b9-c3ae-4575-82ef-ae25b4da90c1",
   "metadata": {},
   "source": [
    "### Themenextraktion mit LDA und Vorbereitung für alternativen Vergleich\n",
    "\n",
    "Die thematische Struktur der Texte wurde mithilfe von LDA (Latent Dirichlet Allocation) analysiert.  \n",
    "Zur Bewertung der Modellqualität wurde der „Coherence Score“ eingesetzt, um die optimale Anzahl an Themen zu bestimmen.\n",
    "\n",
    "In einem separaten Schritt (Notebook 005) wird ergänzend das Verfahren BERTopic eingesetzt.  \n",
    "Dieses nutzt eine andere Methodik zur Themenmodellierung und ermöglicht dadurch eine semantisch differenzierte Betrachtung der Inhalte im Vergleich zu LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe833a4a-4709-4860-bb89-0edd4dd45faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
