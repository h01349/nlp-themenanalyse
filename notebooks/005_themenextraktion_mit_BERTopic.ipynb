{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdd34f6-908c-4b3c-91ab-f729578e8b19",
   "metadata": {},
   "source": [
    "## 005 Themenextraktion mit BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa7734-9f76-4894-97a7-b496b94b6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardbibliotheken\n",
    "import ast\n",
    "\n",
    "# Drittanbieter-Bibliotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CSV-Datei laden (cleaned_data.csv)\n",
    "data = pd.read_csv(\"../data/cleaned_data.csv\")\n",
    "data[\"lemmas_str\"] = data[\"lemmas_str\"].astype(str)\n",
    "\n",
    "# Vortrainierte Embeddings laden (Erzeugt in Notebook 3: ../data/embeddings.npy)\n",
    "embeddings = np.load(\"../data/embeddings.npy\")\n",
    "\n",
    "#print(\"Starte BERTopic-Modellierung: Dies kann einen Moment dauern ...\")\n",
    "\n",
    "# Vektorizer festlegen für bessere Kontrolle über Token\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# BERTopic-Modell initialisieren\n",
    "topic_model = BERTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    language=\"english\",\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Themen mit BERTopic modellieren\n",
    "topics, probs = topic_model.fit_transform(data[\"lemmas_str\"].tolist(), embeddings)\n",
    "\n",
    "# Top-Themen anzeigen (10)\n",
    "print(\"\\nTop 10 Themen:\")\n",
    "print(topic_model.get_topic_info().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d11c7b-ec16-46f8-ab34-16168a1c96b0",
   "metadata": {},
   "source": [
    "### Vergleich der Themenanalyse: LDA vs. BERTopic\n",
    "\n",
    "In diesem Projekt wurden zwei verschiedene Verfahren zur Themenextraktion eingesetzt: LDA und BERTopic.\n",
    "\n",
    "- **LDA** identifiziert Themen auf Basis statistischer Wortverteilungen im Korpus. Die Modellqualität wurde mithilfe der „Coherence Scores“ bewertet. Die resultierenden Themen sind gut interpretierbar, neigen jedoch zu Überschneidungen und zeigen geringere semantische Trennschärfe.\n",
    "\n",
    "- **BERTopic** basiert auf kontextuellen Satz-Embeddings und gruppiert ähnliche Inhalte mithilfe von Clustering-Verfahren. Die Methode liefert thematisch präzisere und klar abgegrenzte Ergebnisse, besonders hilfreich bei komplexeren oder mehrdeutigen Texten.\n",
    "\n",
    "Beide Ansätze ergänzen sich sinnvoll: LDA bietet interpretierbare thematische Grundstrukturen, während BERTopic tiefere semantische Zusammenhänge sichtbar macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2e0d8-c7e4-445f-9309-b3d72b9a75e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
