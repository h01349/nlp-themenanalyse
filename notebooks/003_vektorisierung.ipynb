{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114520af-f5e7-443e-a400-6186ff30897b",
   "metadata": {},
   "source": [
    "## 003 Vektorisierung\n",
    "\n",
    "### TF-IDF\n",
    "- Klassisch, auf Häufigkeiten basierend\n",
    "- Maximale Anzahl an Features: 5000\n",
    "\n",
    "### Sentence Embeddings\n",
    "- Kontextbasiert mit \"sentence-transformers\"\n",
    "- Modell: \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23323636-eac6-425f-a2c8-74f52c844946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Neue CSV-Datei laden (cleaned_data.csv)\n",
    "data = pd.read_csv(\"../data/cleaned_data.csv\")\n",
    "\n",
    "# \"Lemmas\" zurück in Listen\n",
    "data[\"lemmas\"] = data[\"lemmas\"].apply(ast.literal_eval)\n",
    "\n",
    "# Für TF-IDF-Analyse vorbereiten\n",
    "data[\"lemmas_str\"] = data[\"lemmas\"].apply(lambda tokens: \" \".join(tokens))\n",
    "\n",
    "\n",
    "## Schritt 1: TF-IDF-Vektorisierer initialisieren\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,        # Begrenzung auf häufigste (bspw.) 5000 Begriffe\n",
    "    ngram_range=(1, 2),       # Unigramme und Bigramme\n",
    "    stop_words=\"english\"      # zusätzliche englische Stoppwörter entfernen\n",
    ")\n",
    "\n",
    "\n",
    "## Schritt 2: Vektoren erzeugen\n",
    "tfidf_matrix = vectorizer.fit_transform(data[\"lemmas_str\"])\n",
    "\n",
    "\n",
    "## Schritt 3: Ausgabe (Größe der TF-IDF-Matrix)\n",
    "print(\"TF-IDF-Matrix erzeugt.\")\n",
    "print(\"Matrixform:\", tfidf_matrix.shape)\n",
    "\n",
    "## Schritt 4: Sentence Embeddings erzeugen\n",
    "# Hinweis: Beim ersten Ausführen wird das Modell automatisch heruntergeladen. \n",
    "# Dieser Schritt kann einige Sekunden dauern. Danach erfolgt die Nutzung lokal.\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"\\nBerechne semantische Satz-Embeddings: Dies kann einen Moment dauern...\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    data[\"lemmas_str\"].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings-Shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62171561-1b34-41a7-a2a3-fb6120d0b6a9",
   "metadata": {},
   "source": [
    "### Vergleich der Vektorisierungsmethoden:\n",
    "\n",
    "- **TF-IDF** ergibt eine hochdimensionale, spärlich besetzte Matrix mit 5000 \"Features\".\n",
    "- **Sentence Embeddings** liefern dichte Vektoren mit 384 Dimensionen.\n",
    "- TF-IDF ist interpretierbarer, aber semantisch schwächer.\n",
    "- Embeddings sind semantisch reichhaltiger und besser für Clustering geeignet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
